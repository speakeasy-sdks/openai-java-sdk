/* 
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

package openai.javasdk.models.shared;

import com.fasterxml.jackson.annotation.JsonProperty;
import openai.javasdk.utils.SpeakeasyMetadata;


public class CreateTranscriptionRequest {
    /**
     * The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
     * 
     */
    @SpeakeasyMetadata("multipartForm:file")
    public CreateTranscriptionRequestFile file;

    public CreateTranscriptionRequest withFile(CreateTranscriptionRequestFile file) {
        this.file = file;
        return this;
    }
    
    /**
     * The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
     * 
     */
    @SpeakeasyMetadata("multipartForm:name=language")
    public String language;

    public CreateTranscriptionRequest withLanguage(String language) {
        this.language = language;
        return this;
    }
    
    /**
     * ID of the model to use. Only `whisper-1` is currently available.
     * 
     */
    @SpeakeasyMetadata("multipartForm:name=model,json")
    public Object model;

    public CreateTranscriptionRequest withModel(Object model) {
        this.model = model;
        return this;
    }
    
    /**
     * An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
     * 
     */
    @SpeakeasyMetadata("multipartForm:name=prompt")
    public String prompt;

    public CreateTranscriptionRequest withPrompt(String prompt) {
        this.prompt = prompt;
        return this;
    }
    
    /**
     * The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.
     * 
     */
    @SpeakeasyMetadata("multipartForm:name=response_format")
    public String responseFormat;

    public CreateTranscriptionRequest withResponseFormat(String responseFormat) {
        this.responseFormat = responseFormat;
        return this;
    }
    
    /**
     * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
     * 
     */
    @SpeakeasyMetadata("multipartForm:name=temperature")
    public Double temperature;

    public CreateTranscriptionRequest withTemperature(Double temperature) {
        this.temperature = temperature;
        return this;
    }
    
    public CreateTranscriptionRequest(@JsonProperty("file") CreateTranscriptionRequestFile file, @JsonProperty("model") Object model) {
        this.file = file;
        this.model = model;
  }
}
